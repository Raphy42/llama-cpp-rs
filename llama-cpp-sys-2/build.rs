use std::env;
use std::path::Path;
use std::path::PathBuf;

fn workspace_dir() -> PathBuf {
    let output = std::process::Command::new(env!("CARGO"))
        .arg("locate-project")
        .arg("--workspace")
        .arg("--message-format=plain")
        .output()
        .unwrap()
        .stdout;
    let cargo_path = Path::new(std::str::from_utf8(&output).unwrap().trim());
    cargo_path.parent().unwrap().to_path_buf()
}

macro_rules! toggle_if {
    ($name:literal) => {
        if cfg!(target_os = $name) {
            "ON"
        } else {
            "OFF"
        }
    };
}

fn main() {
    println!("cargo:rerun-if-changed=llama.cpp");

    let resource_directory = workspace_dir();
    let llama_directory = resource_directory.join("llama-cpp-sys-2/llama.cpp");
    let dst = cmake::Config::new(&llama_directory)
        .define("LLAMA_STATIC", "ON")
        .define("LLAMA_METAL", toggle_if!("macos"))
        .define("LLAMA_METAL_NDEBUG", toggle_if!("macos"))
        .define("LLAMA_METAL_EMBED_LIBRARY", toggle_if!("macos"))
        .define("LLAMA_CUBLAS", toggle_if!("linux"))
        .define("LLAMA_BLAS", "OFF")
        .define("LLAMA_BUILD_TESTS", "OFF")
        .define("LLAMA_BUILD_EXAMPLES", "OFF")
        .define("LLAMA_BUILD_SERVER", "OFF")
        .define("CMAKE_BUILD_TYPE", "Release")
        .build();
    eprintln!("{:?}", &dst);
    println!(
        "cargo:rustc-link-search=all={}",
        &dst.join("lib").to_string_lossy()
    );

    println!("cargo:rustc-link-lib=static=llama");

    // https://github.com/ggerganov/llama.cpp/blob/191221178f51b6e81122c5bda0fd79620e547d07/Makefile#L133-L141
    if cfg!(target_os = "macos") {
        println!("cargo:rustc-link-lib=dylib=c++");
        println!("cargo:rustc-link-lib=framework=Metal");
        println!("cargo:rustc-link-lib=framework=Foundation");
        println!("cargo:rustc-link-lib=framework=MetalPerformanceShaders");
        println!("cargo:rustc-link-lib=framework=MetalKit");
        println!("cargo:rustc-link-arg=framework=Accelerate");
    }

    let header = "llama.cpp/llama.h";

    println!("cargo:rerun-if-changed={header}");

    let bindings = bindgen::builder()
        .header(header)
        .derive_partialeq(true)
        .no_debug("llama_grammar_element")
        .prepend_enum_name(false)
        .derive_eq(true)
        .generate()
        .expect("failed to generate bindings for llama.cpp");

    let out_path = PathBuf::from(env::var("OUT_DIR").unwrap());
    bindings
        .write_to_file(out_path.join("bindings.rs"))
        .expect("failed to write bindings to file");

    if cfg!(target_os = "macos") {
        use std::fs;

        let from_path = dst.join("build/autogenerated/ggml-metal-embed.metal");
        let to_path = env::current_dir()
            .unwrap()
            .join("ggml-metal.metal");

        match fs::copy(&from_path, &to_path) {
            Ok(_) => {
                eprintln!(
                    "Successfully copied metal shaders file from {:?} to {:?}",
                    from_path, to_path
                );
            }
            Err(e) => panic!("{e:?}"),
        }

        println!("cargo:rustc-link-lib=dylib=c++");
        println!("cargo:rustc-link-lib=framework=Accelerate");
        println!("cargo:rustc-link-lib=framework=Foundation");
        println!("cargo:rustc-link-lib=framework=Metal");
    }
}

